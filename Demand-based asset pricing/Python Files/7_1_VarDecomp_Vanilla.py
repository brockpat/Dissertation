"""
Reads in the Data generated by 6_compute_unpref.py and computes the Variance 
Decomposition.

Select your Inputs below
"""

#%% Define Inputs

#Location of repository
path = ".../Python Replication Package" 

#Select Restricted Estimates
filename = 'BackwardSelection_GMM_NoIV'
#(LASSO_IV, LASSO, ADAPTIVE_LASSO_OLSWEIGHTS, BackwardSelection_IV2SLS, BackwardSelection_GMM_NoIV, KY19_baseline, all, NLLS)

#Select Quarter on which the Variance Decomposition is computed (KY19 use 2nd quarter of every year)
q = 2
#%% Libraries
import pandas as pd
import numpy as np
import scipy
import copy

#Import self-written Functions for the Variance Decomposition. This file is in the same folder
from Functions_VarDecomp import *

#%% Load Data

#Load StocksQ which contains observed annual return and the dividend return
StocksQ = pd.read_stata(path + "/Data" + "/StocksQ.dta")
StocksQ["date"] = StocksQ["date"] - pd.offsets.MonthBegin()+pd.offsets.MonthEnd()

#%% Root Finding

"""
Holdings Dataset Description:
----------------------------
    Rows:   Individual Investor (mgrno --> mgrno == 0 are households) 
            at a certain time period (rdate)
            holding a certain stock (permno)
            with portfolio weight LNrweight (in logs)
            with certain value of assets under management (aum) in million $

"""

#Define Dictionaries used in the root-finding loop to extract the correct quarter
day_dict = {1:"31", 2:"30", 3:"30", 4:"31"}
month_dict = {1:"03", 2:"06", 3:"09", 4:"12"}


#Define Dataframes to store results
df_results = pd.DataFrame()
df_numerical_errors = pd.DataFrame(columns = ['rdate','root1_error','root2_error','root3_error','root4_error','root5_error'])

#Loop over second quarter of all consecutive years
for year in range(2007, 2008):
    print("------------------------------------------- \n" + 
          "------------------------------------------- \n \n" +
          "              YEAR = " + str(year) + "\n \n" + 
          "------------------------------------------- \n" + 
          "------------------------------------------- \n")
    #---------------------------------------------------------------------#
    # 1) Read in Datasets
    #---------------------------------------------------------------------#
    
    #---- Read in time t Data
    prev_VarDecomp_df = pd.read_stata(path + "/Output/Variance Decomposition Python/" + f"VarDecomp_{filename}_Restricted_{year}"f"-{month_dict[q]}"f"-{day_dict[q]}.dta")
    prev_VarDecomp_df['rdate'] =  pd.to_datetime(prev_VarDecomp_df["rdate"])
    
    #Drop Stocks that are not held by ANY investor 
    prev_VarDecomp_df = prev_VarDecomp_df[prev_VarDecomp_df.groupby("permno").LNrweight.transform("count")>0]
    
    #Drop Zero Holdings of each Investor (Demand is zero and needn't be explicitly computed)
    prev_VarDecomp_df = prev_VarDecomp_df.dropna(subset = 'LNrweight')
    
    #Sort dataframe (extremely important!)
    #   If not sorted, then in getObjects() while iterating over managers and stocks the indices
    #   might not refer to same manager or stock for the outputs
    prev_VarDecomp_df = prev_VarDecomp_df.sort_values(['mgrno','permno'])

    
    #----Read in time t+4 Holdings Data
    Lead_VarDecomp_df = pd.read_stata(path + "/Output/Variance Decomposition Python/" + f"VarDecomp_{filename}_Restricted_{year + 1}"f"-{month_dict[q]}"f"-{day_dict[q]}.dta")
    Lead_VarDecomp_df['rdate'] =  pd.to_datetime(Lead_VarDecomp_df["rdate"]) #if reading in csv
    
    #Drop Stocks that are not held by ANY investor (Asset Demand System not applicable to these Stocks)
    Lead_VarDecomp_df = Lead_VarDecomp_df[Lead_VarDecomp_df.groupby("permno").LNrweight.transform("count")>0]
    
    #Drop Zero Holdings of each Investor (since demand is zero it needn't be explicitly computed)
    Lead_VarDecomp_df = Lead_VarDecomp_df.dropna(subset = 'LNrweight')
    
    #Sort dataframe (extremely important!)
    #   If not sorted, then in getObjects() while iterating over managers and stocks the indices
    #   might not refer to same manager or stock for the outputs
    Lead_VarDecomp_df = Lead_VarDecomp_df.sort_values(['mgrno','permno'])
            
        
    #---------------------------------------------------------------------#
    # 2) Get Objects
    #---------------------------------------------------------------------#
    
    #These Objects are used for the root-finding process
    prev_PFRweight, prev_PFRweightMat, prev_Epsilon, prev_EpsilonMat, prev_cons, prev_consMat, \
        prev_RegCoeffs, prev_RegCoeffsMat, prev_aum, prev_aumVec, prev_p, prev_s, prev_x, prev_uniquePermno, prev_LNcfac = getObjects(prev_VarDecomp_df, year, q)
      
    
    #---------------------------------------------------------------------#
    # 3) Lead supply, characteristics, aum, beta coefficients and compute
    #        the intermediary market clearing price
    #---------------------------------------------------------------------#
    
    #----- i) Lead shares Outstanding (Supply)

    #Compute the intermediary price resulting from a ceteris paribus supply change.
    print("------------------------------------------- \n" + 
          "              Leading Supply" + "\n"
          + "-------------------------------------------")
    
    #-- Update Supply of Stocks that are still held in t+4
    #Create Dataframe with Supply_t and Supply_{t+4} for stocks at time t
    Lead_s = prev_s.merge(Lead_VarDecomp_df[['permno','LNshrout']].drop_duplicates(subset = 'permno'), how='left', 
                           on='permno', suffixes=('', '_Lead'))
    #Update Supply_t with values from S_{t+4} if they exist.
    Lead_s['LNshrout'] = np.where(pd.notnull(Lead_s['LNshrout_Lead']), Lead_s['LNshrout_Lead'], Lead_s['LNshrout'])
    #Delete auxiliary column
    Lead_s.drop('LNshrout_Lead',axis = 1, inplace = True)
    
    #Convert to numpy array
    Lead_sVec = Lead_s.set_index('permno').values.reshape(-1)

    #Solve for the Market Clearing Price
    root1 = solve_MarketClearing(prev_p["LNprc"].to_numpy(), 
                                 Lead_sVec, prev_x, prev_aumVec, prev_RegCoeffsMat, prev_EpsilonMat, prev_consMat)
    print("Root1 Approximation Error = " + str(np.linalg.norm(root1.fun)))
    
    #Save Results
    LNprc_1 = prev_p.copy()
    LNprc_1.loc[:, 'LNprc'] = root1.x 
    LNprc_1 = LNprc_1.rename(columns = {'LNprc':'LNprc_1'})
    

    #----- ii) Lead Stock Characteristics X
    
    #Compute the intermediary price resulting from a ceteris paribus Stock characteristics change.
    print("------------------------------------------- \n" + 
          "          Leading Characteristics" + "\n"
          + "-------------------------------------------")
    
    #-- Update Characteristics of Stocks that are still held in t+4
    # Create lists of stock characteristics for the current and lead time periods
    x_list = [item for item in prev_x.columns if item not in ['permno', 'constant']]
    x_list_lead = [item + "_Lead" for item in prev_x.columns if item not in ['permno','constant']]
    
    #Update x_t with values from x_{t+4} if they exist
    Lead_x = prev_x.merge(Lead_VarDecomp_df[['permno'] + x_list].drop_duplicates(subset = 'permno'), 
                          how='left', 
                          on='permno', suffixes=('', '_Lead'))
    
    #Update x_t with values from t+4 if they exist.
    Lead_x[x_list] = np.where(pd.notnull(Lead_x[x_list_lead]), Lead_x[x_list_lead], Lead_x[x_list])
    #Delete auxiliary column
    Lead_x.drop(x_list_lead,axis = 1, inplace = True)
    
    #Solve for the Market Clearing Price
    root2 = solve_MarketClearing(LNprc_1['LNprc_1'].to_numpy(), 
                                 Lead_sVec, Lead_x, prev_aumVec, prev_RegCoeffsMat, prev_EpsilonMat, prev_consMat)
    print("Root2 Approximation Error = " + str(np.linalg.norm(root2.fun)))
    
    #Save Results
    LNprc_2 = prev_p.copy()
    LNprc_2.loc[:, 'LNprc'] = root2.x
    LNprc_2 = LNprc_2.rename(columns = {'LNprc':'LNprc_2'})
    
    
    #----- iii) Lead AUM 
   
    #Compute the intermediary price resulting from a ceteris paribus AUM Change.
    print("------------------------------------------- \n" + 
          "              Leading AUM" + "\n"
          + "-------------------------------------------")
    
    #-- Update AUM of Managers who still exist in t+4
    #Create Dataframe with aum_t and aum_{t+4} for stocks at time t
    Lead_aum = prev_aum.merge(Lead_VarDecomp_df[['mgrno','aum']].drop_duplicates(subset = 'mgrno'), how='left', 
                           on='mgrno', suffixes=('', '_Lead'))
    #Update aum_t with values from t+4 if they exist.
    Lead_aum['aum'] = np.where(pd.notnull(Lead_aum['aum_Lead']), Lead_aum['aum_Lead'], Lead_aum['aum'])
    #Delete auxiliary column
    Lead_aum.drop('aum_Lead',axis = 1, inplace = True)
    #Convert to numpy array
    Lead_aumVec = Lead_aum.set_index('mgrno').values.reshape(-1)
    
    #Solve for the Market Clearing Price
    root3 = solve_MarketClearing(LNprc_2['LNprc_2'].to_numpy(), 
                                 Lead_sVec, Lead_x, Lead_aumVec, prev_RegCoeffsMat, prev_EpsilonMat, prev_consMat)
    print("Root3 Approximation Error = " + str(np.linalg.norm(root3.fun)))
    
    #Save Results
    LNprc_3 = prev_p.copy()
    LNprc_3.loc[:, 'LNprc'] = root3.x
    LNprc_3 = LNprc_3.rename(columns = {'LNprc':'LNprc_3'})
    
    #----- iv) Lead  betas (coefficients) & 'cons' 
    
    #Compute the intermediary price resulting from a ceteris paribus Beta change
    print("------------------------------------------- \n" + 
          "          Leading Beta & 'cons' " + "\n"
          + "-------------------------------------------")
    
    #Extract the relevant columns
    beta_list = list(prev_RegCoeffs.columns) + ['cons']
    beta_list_Lead = [item + "_Lead" for item in beta_list]
    
    #Create a dataframe with Lead values
    Lead_RegCoeffs = prev_VarDecomp_df[['mgrno','permno'] + beta_list].merge(
        Lead_VarDecomp_df[beta_list + ['mgrno']].drop_duplicates(subset = 'mgrno'),
                                                                  on = 'mgrno', how = 'left',
                                                                  suffixes = ("", "_Lead"))
    
    #Update beta & cons with values from t+4 if they exist
    Lead_RegCoeffs[beta_list] = np.where(pd.notnull(Lead_RegCoeffs[beta_list_Lead]), Lead_RegCoeffs[beta_list_Lead], Lead_RegCoeffs[beta_list])
    #Delete auxiliary column
    Lead_RegCoeffs.drop(beta_list_Lead,axis = 1, inplace = True)
    
    #Create RegCoeffsMat
    Lead_RegCoeffsMat = Lead_RegCoeffs.drop_duplicates(subset = 'mgrno')[beta_list].drop('cons',axis=1).to_numpy()
    #Create consMat
    Lead_consMat = np.nan_to_num(Lead_RegCoeffs.pivot_table(index='mgrno', columns=['permno'], values='cons').to_numpy(),0)
    
    #Solve for the Market Clearing Price
    root4 = solve_MarketClearing(LNprc_3['LNprc_3'].to_numpy(), 
                                 Lead_sVec, Lead_x, Lead_aumVec, Lead_RegCoeffsMat, prev_EpsilonMat, Lead_consMat)
    print("Root4 Approximation Error = " + str(np.linalg.norm(root4.fun)))
    
    #Save Results
    LNprc_4 = prev_p.copy()
    LNprc_4.loc[:, 'LNprc'] = root4.x
    LNprc_4 = LNprc_4.rename(columns = {'LNprc':'LNprc_4'})
    
    #---------------------------------------------------------------------#
    # 4) Update Investment universe
    #---------------------------------------------------------------------#

    print("------------------------------------------- \n" + 
          "          Extensive Margin" + "\n"
          + "-------------------------------------------")

    #Merge unpref from t to unpref in t+4
    prev_unpref = Lead_VarDecomp_df[['mgrno','permno','unpref']].merge(
        prev_VarDecomp_df[['mgrno','permno','unpref']], how = 'left',
        on = ['mgrno', 'permno'], suffixes=('', '_prev'))
    
    #Downgrade the values from t+4 back to t if downgrade exists
    prev_unpref['unpref'] = np.where(pd.notnull(prev_unpref['unpref_prev']), prev_unpref['unpref_prev'], prev_unpref['unpref'])
    prev_unpref.drop('unpref_prev',axis = 1, inplace = True)
    
    #Merge Downgraded Values to the DataFrame at time t+4
    Lead_VarDecomp_df = Lead_VarDecomp_df.merge(prev_unpref, on = ['mgrno','permno'], how = 'left', 
                                      suffixes = ("","_Lag"))
            
    Lead_VarDecomp_df.drop('unpref',axis = 1, inplace = True)
    Lead_VarDecomp_df = Lead_VarDecomp_df.rename(columns = {'unpref_Lag':'unpref'})


    #Get Objects for the Root Finding
    Lead_PFRweight, Lead_PFRweightMat, prev_Epsilon, prev_EpsilonMat, Lead_cons, Lead_consMat, \
        Lead_RegCoeffs, Lead_RegCoeffsMat, Lead_aum, Lead_aumVec, Lead_p, Lead_s, Lead_x, \
            Lead_uniquePermno, Lead_LNcfac = getObjects(Lead_VarDecomp_df, year + 1, q)
    
    
    #Compute the Market Clearing Price (notice: Price has different dimension as t+4 data has different permnos than t data)
    root5 = solve_MarketClearing(Lead_p["LNprc"].to_numpy(),
                                 Lead_s['LNshrout'].to_numpy(), Lead_x, Lead_aumVec, Lead_RegCoeffsMat, prev_EpsilonMat, Lead_consMat)
    print("Root5 Approximation Error = " + str(np.linalg.norm(root5.fun)))
    
    #Save Results
    LNprc_5 = Lead_p.copy()
    LNprc_5.loc[:, 'LNprc'] = root5.x
    LNprc_5 = LNprc_5.rename(columns = {'LNprc':'LNprc_5'})
    
    #---------------------------------------------------------------------#
    # 5)  Compute Intermediary Returns & Save Final Returns
    #---------------------------------------------------------------------#
    
    #---------------------- Assemble Price Data -------------------------------
    
    #Save LNprc1 to LNprc6 in one dataframe --> LNprc6 is the actual observed price at t+4
    df_LNprc = (prev_p
                .rename(columns = {'LNprc':'LNprc_prev'})
                .merge(LNprc_1, on = "permno", how = 'outer', suffixes = ("", ""))
                )
    df_LNprc = df_LNprc.merge(LNprc_2, on = "permno", how = 'outer', suffixes = ("", ""))
    df_LNprc = df_LNprc.merge(LNprc_3, on = "permno", how = 'outer', suffixes = ("", ""))
    df_LNprc = df_LNprc.merge(LNprc_4, on = "permno", how = 'outer', suffixes = ("", ""))
    df_LNprc = df_LNprc.merge(LNprc_5, on = "permno", how = 'outer', suffixes = ("", ""))
    df_LNprc = (df_LNprc
                .merge((Lead_VarDecomp_df
                        .rename(columns = {'LNprc':'LNprc_6'})[['permno','LNprc_6']]
                        .drop_duplicates('permno')
                        ),
                       how = 'outer', suffixes = ("","")
                       )
                .sort_values('permno')
                )

    #Merge LNcfac & only keep Stocks that exist in both t and t+4 by inner merge
    df_LNprc = (df_LNprc
                .merge(prev_LNcfac.reset_index(), on = 'permno', how = 'inner')
                .rename(columns = {'LNcfac': 'LNcfac_prev'})
                )
    
    df_LNprc = (df_LNprc
                .merge(Lead_LNcfac.reset_index(), on = 'permno', how = 'inner')
                .rename(columns = {'LNcfac': 'LNcfac_Lead'})
                )
    
    #-------------------- Compute intermediary Returns-------------------------
    
    #Compute The intermediary returns
    df_LNprc['LNret1'] 	= df_LNprc['LNprc_1']+df_LNprc['LNcfac_Lead']-(df_LNprc['LNprc_prev']+ df_LNprc['LNcfac_prev'])
    for i in range(2, 7):
        df_LNprc[f'LNret{i}'] = df_LNprc[f'LNprc_{i}'] - df_LNprc[f'LNprc_{i-1}']
    
    
    #-------------------- Assemble Final Dataframe ----------------------------
    
    #Drop LNcfac as it is no longer required
    df_LNprc = df_LNprc.drop(['LNcfac_prev','LNcfac_Lead'],axis = 1)
    
    #Add date column that enables the inclusion of time fixed effects
    df_LNprc['rdate'] = Lead_VarDecomp_df['rdate'][0]
    
    #Merge observed final annual and dividend return
    df_LNprc = df_LNprc.merge(StocksQ[['date','permno','LNretA','LNretdA']], 
                              left_on = ['rdate','permno'], right_on = ['date','permno'], 
                              suffixes = ("","")).drop("date",axis=1)
    
    #Append results
    df_results = pd.concat([df_results,df_LNprc])

    #--------------- Save the numerical Root-finding errors -------------------
    df_error= pd.DataFrame(columns = ['rdate', 'root1_error',
                                      'root2_error','root3_error',
                                      'root4_error','root5_error'])

    df_error.loc[0] = [
        Lead_VarDecomp_df["rdate"][0],
        np.linalg.norm(root1.fun),
        np.linalg.norm(root2.fun),
        np.linalg.norm(root3.fun),
        np.linalg.norm(root4.fun),
        np.linalg.norm(root5.fun)#, 
            ]
    df_numerical_errors = pd.concat([df_numerical_errors,df_error])
    
    #-------------------------   Export Results ---------------------------
    df_results.to_stata(path + "/Output/Variance Decomposition Python/" + filename + "_IntermediaryReturns.dta",
                        write_index=False)
    df_numerical_errors.to_csv(path + "/Output/Variance Decomposition Python/" + filename + "_IntermediaryReturns_NumERRORS.csv")
